{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "musical-director",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ICESat-2 Data Tutorial\n",
    "---\n",
    "This notebook is designed to give you a first look at ICESat-2 data (the Ice, Cloud, and land Elevation Satellite, 2). There are a range of data products generated from the raw output of the instrument, which fall into categories defined by the processing level:\n",
    "\n",
    "* L0 -- Reconstructed, unprocessed data at full resolution (no sane person would ever look at L0 data)\n",
    "* L1 -- The same reconstructed, unprocessed data, but includes ancillary information (for example, calibration parameters and georeferencing information) and is often calibrated / converted to physical units (instead of instrument voltages, which are often the fundamental measurement).\n",
    "* L2 [The lowest level we would ever look at] -- Derived geophysical parameters at the same resolution as the L1 data\n",
    "* L3 [The most common level to use] -- Data, derived from L2 products, that has been spatially or temporally resampled, and analyzed for additional geophysical properties.\n",
    "\n",
    "For our purposes here, we look at the following heirarchy of products\n",
    "* ATL03 [L2] -- The time, latitude, longitude, and ellipsoidal height for each photon event downlinked from ATLAS.\n",
    "* ATL06 [L3] -- The geolocated estimates of land-ice surface heights and ancillary parameters that can be used to interpret the estimates and assess their quality. Photon events are aggregated into overlapping, along-track segments of a fixed length (40 m) whose centers are 20 meters apart, and the algorithm estimates the along-track slope and height at the center of each segment. \n",
    "* ATL11 [L3] -- The time series of surface heights. It is the lowest-level land-ice product that brings together data from multiple passes over the same points, obviating the need to collect individual ATL06 files for this task.\n",
    "* ATL15 [L3B] -- Gridded Antarctic and Arctic Land Ice Height Change\n",
    "---\n",
    "To look at the data, I start by importing a series of modules that will be useful for reading and plotting the data. The ICESat-2 read functions come from Tyler Sutterly's github account (a current Postdoc at the University of Washington - https://github.com/tsutterley)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "weighted-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sys and glob are useful tools for dealing with the local filesystem.\n",
    "import sys   \n",
    "import glob\n",
    "\n",
    "### numpy and matplotlib are the core analysis packages for manipulating and plotting data arrays\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "\n",
    "### Here, we import the local data read utilities from TS\n",
    "import icesat2_toolkit.utilities\n",
    "from icesat2_toolkit.read_ICESat2_ATL03 import read_HDF5_ATL03\n",
    "from icesat2_toolkit.read_ICESat2_ATL06 import read_HDF5_ATL06\n",
    "from icesat2_toolkit.read_ICESat2_ATL11 import read_HDF5_ATL11\n",
    "\n",
    "### Xarray is a great tool for reading NetCDF files, which are the structure for ATL14 and ATL15\n",
    "import xarray\n",
    "\n",
    "### finally, pyproj is a useful tool for converting geographic coordinates (lat/Lon) to local coordinate systems\n",
    "from pyproj import Transformer\n",
    "### this transformer object is designed to convert latitude/longitude to Antarctic Polarstereographic coordinates.\n",
    "transformer = Transformer.from_crs(\"epsg:4326\", \"epsg:3031\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "excess-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "### In addition, we use something here called a Jupyter \"Magick\" -- this line changes the back-end of how Jupyter treats matplotlib plots.\n",
    "### Instead of producing static images, the matplotlib widget allows you to zoom and pan and interrogate the plot interactively.\n",
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-brush",
   "metadata": {},
   "source": [
    "# ATL03 - Global Geolocated Photon Data\n",
    "---\n",
    "As stated above, ATL03 is the geolocated photon product. This can be a somewhat cumbersome product to work with, but it is the basis for all of the higher level products, so it is useful to get a sense for how it is structured. Here are a few useful resources for understanding the structure of the files containing ATL03 data.\n",
    "\n",
    "ATL03 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL03_data_dict_v004.pdf\n",
    "\n",
    "ATL03 File Naming Convention: ATL03_[yyyymmdd][hhmmss]\\_[ttttccss]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* cc = Cycle\n",
    "* ss = Region\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "---\n",
    "To start working with the data, you can either find the file in the local data directory using the package `glob` (identifying any files with names that start with \"ATL03\") or download it directlty from the web. The cell below will first try and download the file to your local directory. If it already exists, it will instead simply read the file. \n",
    "\n",
    "The output of the read function is a tuple, which contains dictionaries for each file read. Because I want the `data` object to simply be a dictionary, I immediately select just the first entry in the tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b51a4a6-ec13-4b5f-960f-91fb40a6c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### On Wednesdays, the NSIDC servers undergo maintenance, and so data download during that period will not work.\n",
    "\n",
    "# On normal days, the NSIDC query requires that you have a file in your home directory called .netrc that contains\n",
    "# the following info:\n",
    "### machine urs.earthdata.nasa.gov login [uname] password [pwd]\n",
    "\n",
    "try:\n",
    "    # get ATL03 and ATL06 granules\n",
    "    for shortname in ['ATL03','ATL06']:\n",
    "        ids,urls = icesat2_toolkit.utilities.cmr(product=shortname,release='005',\n",
    "            cycles=9,tracks=256,granules=10,verbose=False)\n",
    "        # for each granule url from NSIDC\n",
    "        for id,url in zip(ids,urls):\n",
    "            icesat2_toolkit.utilities.from_nsidc(url, local=id, verbose=True)\n",
    "\n",
    "    # get ATL11 granules\n",
    "    ids,urls = icesat2_toolkit.utilities.cmr(product='ATL11',release='004',\n",
    "        tracks=256,granules=10,verbose=False)\n",
    "\n",
    "    # get ATL15 Gridded product\n",
    "    ids,urls = icesat2_toolkit.utilities.cmr(product='ATL15',release='001',regions='AA',\n",
    "        resolutions='01km',verbose=False)\n",
    "\n",
    "    # for each granule url from NSIDC\n",
    "    for id,url in zip(ids,urls):\n",
    "        icesat2_toolkit.utilities.from_nsidc(url, local=id, verbose=True)\n",
    "        \n",
    "except:\n",
    "    fn = glob.glob('ATL03*')\n",
    "    data_03 = read_HDF5_ATL03(fn[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-romantic",
   "metadata": {},
   "source": [
    "\n",
    "Exploring dictionaries often involves a lot of the `.keys` method -- remember, dictionaries store data as \"key/value pairs\", so if you want to see the different storage fields, those are listed as the `keys`. The data dictionary linked above provides text-definitions of each of the keys, but you will find that the details of the data sit within first a \"ground track\" group (e.g., 'gt1l') and then the \"heights\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_03['gt1l']['heights'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f35adb-7d7f-43c1-bac9-7f80e16514c5",
   "metadata": {},
   "source": [
    "---\n",
    "To minimize duplication in the data structure, the photon level data are grouped into segments, and their position information is all referenced to the position of a single photon within that segment. The block of code below virst identifies the index for every photons reference, and then adds the relative position to the absolute position of the reference photon to create an along-track coordinage, named `ph_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "standing-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_cnt = np.array(data_03['gt1l']['geolocation']['segment_ph_cnt'])\n",
    "seg_cnt = np.concatenate([np.atleast_1d(0),seg_cnt])\n",
    "seg_cnt = np.cumsum(seg_cnt)\n",
    "\n",
    "\n",
    "ref_index = np.zeros(data_03['gt1l']['heights']['signal_conf_ph'][:,4].shape,dtype=np.int32)\n",
    "for i,ind_ref in enumerate(seg_cnt[:-1]):\n",
    "    ref_index[ind_ref:seg_cnt[i+1]] = i\n",
    "\n",
    "    \n",
    "ph_x = data_03['gt1l']['heights']['dist_ph_along']+data_03['gt1l']['geolocation']['segment_dist_x'][ref_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-andrews",
   "metadata": {},
   "source": [
    "---\n",
    "Every photon within the ATL03 product is given a \"confidence classification\", identifying if it is likely signal or noise. We can plot all of the photons as a function of their position along the ground track, color coded and sized by their confidence value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "compatible-uncertainty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272ecfd051b34e67b68d37bae735bb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Distance Along Track (m)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Here we define the limits to good data\n",
    "start_xatc = 28500000\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,12))\n",
    "sizes = [0.1,0.2,0.4,0.9,1.5]\n",
    "sizes = [1,1,1,1,1]\n",
    "confs = [0,1,2,4]\n",
    "\n",
    "############ And then we plot!\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "for i, conf_vals in enumerate(confs):\n",
    "    keep_inds = np.where(np.all([[data_03['gt1l']['heights']['signal_conf_ph'][:,3] == conf_vals],[ph_x > 300000+start_xatc],[ph_x < 400000+start_xatc]],axis=0)[0])\n",
    "    plt.plot(ph_x[keep_inds]-start_xatc,data_03['gt1l']['heights']['h_ph'][keep_inds],'.',ms=sizes[i],color=cmocean.cm.ice(color_inds[i]))\n",
    "\n",
    "plt.ylabel('Elevation (m)')\n",
    "plt.xlabel('Distance Along Track (m)')\n",
    "#plt.xlim(300000,301000)\n",
    "#plt.ylim(1420,1430)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5fe7d-3225-4789-b621-a84cf921ed13",
   "metadata": {},
   "source": [
    "Fitting of high confidence photons is then used to generate the ATL06 product, which we describe in more detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-dependence",
   "metadata": {},
   "source": [
    "# ATL06 - Land Ice Height\n",
    "---\n",
    "ATL06 uses a surface finding algorithm to determine the position and slope of the ice sheet surface. \n",
    "\n",
    "ATL06 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL06_data_dict_v004.pdf\n",
    "\n",
    "ATL06 File Naming Convention: ATL06_[yyyymmdd][hhmmss]\\_[ttttccss]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* cc = Cycle\n",
    "* ss = Region\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "---\n",
    "As before, we read in the first file with a name starting \"ATL06\". I show here the keys of that file, which are the highest level groups in the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranking-typing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gt1l', 'gt1r', 'gt2l', 'gt2r', 'gt3l', 'gt3r', 'orbit_info', 'quality_assessment', 'ancillary_data'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = glob.glob('ATL06*')\n",
    "data_06 = read_HDF5_ATL06(fn[0])[0]\n",
    "data_06.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8165931-191f-444b-a951-c506b9dd0b9a",
   "metadata": {},
   "source": [
    "---\n",
    "Most of the variabiles of interest live within the \"land_ice_segments\" group, so it is worth looking at those groups here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "psychological-ontario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bias_correction', 'dem', 'fit_statistics', 'geophysical', 'ground_track', 'atl06_quality_summary', 'delta_time', 'h_li', 'h_li_sigma', 'latitude', 'longitude', 'segment_id', 'sigma_geo_h'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_06['gt1l']['land_ice_segments'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee6024-4a9b-4904-a5e3-de3c7f9e6daf",
   "metadata": {},
   "source": [
    "---\n",
    "Here, we can plot the fit segments on top of the ATL03 data, to demonstrate exactly where ATL06 comes from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "introductory-leone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f681e862e057469f98ede9c16f2150da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ground Track 1, Left Beam')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start_xatc = data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'][0]\n",
    "\n",
    "############ Here we regenerate the ATL03 plot\n",
    "plt.figure()\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,6))\n",
    "sizes = [0.1,0.2,0.4,0.9,1.5]\n",
    "sizes = [1,1,1,1,1]\n",
    "confs = [0,1,2,4]\n",
    "for i, conf_vals in enumerate(confs):\n",
    "    keep_inds = np.where(np.all([[data_03['gt1l']['heights']['signal_conf_ph'][:,4] == conf_vals],[ph_x > 300000+start_xatc],[ph_x < 400000+start_xatc]],axis=0)[0])\n",
    "    plt.plot(ph_x[keep_inds]-start_xatc,data_03['gt1l']['heights']['h_ph'][keep_inds],'.',ms=sizes[i],color=cmocean.cm.ice_r(color_inds[i]))\n",
    "\n",
    "\n",
    "############ Here we define the limits to good data\n",
    "keep_inds = np.where(np.all([[data_06['gt1l']['land_ice_segments']['atl06_quality_summary'] == 0],[data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'] > 300000+start_xatc],[data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'] < 400000+start_xatc]],axis=0)[0])\n",
    "\n",
    "############ Here we build up the segment coordinates\n",
    "at_x = np.squeeze(data_06['gt1l']['land_ice_segments']['ground_track']['x_atc'][keep_inds]-start_xatc)\n",
    "\n",
    "at_x1 = at_x - 20;\n",
    "at_x2 = at_x + 20;\n",
    "at_y1 = data_06['gt1l']['land_ice_segments']['h_li'][keep_inds] - 20*data_06['gt1l']['land_ice_segments']['fit_statistics']['dh_fit_dx'][keep_inds]\n",
    "at_y2 = data_06['gt1l']['land_ice_segments']['h_li'][keep_inds] + 20*data_06['gt1l']['land_ice_segments']['fit_statistics']['dh_fit_dx'][keep_inds]\n",
    "\n",
    "############ We assemble the multidimensional array\n",
    "at_x_final = np.array([[at_x1],[at_x2]]).squeeze()\n",
    "at_y_final = np.array([[at_y1],[at_y2]]).squeeze()\n",
    "\n",
    "plt.plot(at_x_final,at_y_final,color='black')\n",
    "\n",
    "plt.ylabel('Elevation (m)')\n",
    "plt.xlabel('Distance Along Track (m)')\n",
    "plt.title('Ground Track 1, Left Beam')\n",
    "#plt.xlim(340400,340600)\n",
    "#plt.ylim(315,320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364b0c32-d908-429a-98f8-8c3566591b47",
   "metadata": {},
   "source": [
    "---\n",
    "It can be useful to see where, on the ground, our tracks lie. Here I have the tracks plotted against the ATL14 product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "grave-hundred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a37e9cbb4542eb9400e65712ab2fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beams = ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']\n",
    "\n",
    "plt.figure()\n",
    "for i,beam_opts in enumerate(beams):\n",
    "    x,y = transformer.transform(data_06[beam_opts]['land_ice_segments']['latitude'],data_06[beam_opts]['land_ice_segments']['longitude'])\n",
    "    plt.plot(x[keep_inds],y[keep_inds],'.',ms=1,color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-radar",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ATL11 - Land-ice H(t)\n",
    "---\n",
    "ATL11 uses repeat observations of ATL06 to determine the height change through time. This uses each beam pair to determine the cross-track slope, to correct for height changes that are not due to changes in the glacier system but instead due to imprecision in the ground-track position.\n",
    "\n",
    "ATL11 Data Dictionary: https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL11_data_dict_v003.pdf\n",
    "\n",
    "ATL11 File Naming Convention: ATL11_[tttt][ss]\\_[cccc]\\_[vvv_rr].h5\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* ss = Region\n",
    "* cccc = First and last cycles of data included in the file\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "As always, we start by reading in the file, and looking at the keys of the resulting dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civilian-abortion",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pt1', 'pt2', 'pt3', 'orbit_info', 'quality_assessment', 'ancillary_data'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['cycle_number', 'delta_time', 'h_corr', 'h_corr_sigma', 'h_corr_sigma_systematic', 'latitude', 'longitude', 'quality_summary', 'ref_pt', 'cycle_stats'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = glob.glob('ATL11*')\n",
    "data11 = read_HDF5_ATL11(fn[0])[0]\n",
    "print(data11.keys())\n",
    "data11['pt1'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33739a30-f8f9-4279-b7fe-73dacabaf2d6",
   "metadata": {},
   "source": [
    "---\n",
    "Within the ATL11 data structure, there are rows in the h_corr object that signifiy the height during different cycles of data acquisition. You can see those height change results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "radio-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba3f482c70c435f98da2eae91d0076e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0fcb7ffd30>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "color_inds = np.uint16(np.linspace(0,256,10))\n",
    "\n",
    "for i,cycles in enumerate(data11['pt1']['cycle_number']):\n",
    "    keep_inds = np.where(np.all([[data11['pt1']['quality_summary'][:,i] == 0],[data11['pt1']['h_corr'][:,i] < 1e4]],axis=0)[0])\n",
    "    plt.plot(data11['pt1']['ref_pt'][keep_inds],np.squeeze(data11['pt1']['h_corr'][keep_inds,i]),'.',color=cmocean.cm.ice_r(color_inds[i]),label='Cycle '+str(cycles))\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c73b6-2417-4cf2-a7cf-ba439c5fb74a",
   "metadata": {},
   "source": [
    "# ATL15 - Gridded Antarctic and Arctic Land Ice Height Change\n",
    "---\n",
    "This data set (ATL15) and ATL14 bring the time-varying height estimates provided in ATLAS/ICESat-2 L3B Annual Land Ice Height (ATL11) into a gridded format. \n",
    "\n",
    "ATL15 Data Dictionary: \n",
    "https://nsidc.org/sites/nsidc.org/files/technical-references/ICESat2_ATL15_data_dict_v001.pdf\n",
    "\n",
    "ATL15 File Naming Convention: ATL15_\\[RR]_\\[CCCC]_\\[nn]km_\\[vvv_rr]\n",
    "\n",
    "\n",
    "* tttt = Reference Ground Track (RGT)\n",
    "* RR = RegionAntarctica = AA; Alaska = AK; Arctic Canada North = CN; Arctic Canada South = CS; Greenland and peripheral ice caps = GL; Iceland = IS; Svalbard = SV; Russian Arctic = RA.\n",
    "* cccc = First and last cycles of data included in the file\n",
    "* nn = Two-digit spatial resolution. Options are 01, 10, 20, and 40\n",
    "* vvv_rr = Version and revision number\n",
    "\n",
    "As always, we start by reading in the file -- this time using the package xarray (which is designed for gridded datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95dc47-2605-41a3-9336-9fab44983517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc6fd7-66d3-4872-bdda-284aff4a4d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
